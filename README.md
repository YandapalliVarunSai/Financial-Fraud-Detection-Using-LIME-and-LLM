# ğŸ’° Financial Fraud Detection Using LIME and LLM

> **Stacked Machine Learning** meets **Explainable AI (LIME)** and **Large Language Models (LLM)** to build an **interpretable, high-accuracy financial fraud detection system**.  
> Designed for real-world banking transactions â€” blending performance, explainability, and trust.

ğŸ”— **GitHub Repository:** [YandapalliVarunSai/Financial-Fraud-Detection-Using-LIME-and-LLM](https://github.com/YandapalliVarunSai/Financial-Fraud-Detection-Using-LIME-and-LLM)

---

## ğŸš€ Project Overview

This project develops an **intelligent, explainable, and accurate financial fraud detection system** using **Stacked Machine Learning**, **LIME (Explainable AI)**, and **Sonar Pro LLM** for natural-language interpretation.

It aims to:
- Detect fraudulent transactions with **91% accuracy**
- Explain **why** a prediction was made (via LIME)
- Generate **human-readable insights** from LIME using LLM

The system enhances **transparency**, **trust**, and **regulatory compliance** â€” bridging the gap between machine predictions and human understanding.

---

## ğŸ§  Architecture Overview

```
Raw Transaction Data (Kaggle)
        â”‚
        â–¼
 Data Preprocessing
 (Encoding, SMOTE, Scaling)
        â”‚
        â–¼
 Feature Selection
 (Random Forest Top Features)
        â”‚
        â–¼
 Model Training
 (LR, DT, RF, AdaBoost, XGBoost)
        â”‚
        â–¼
 Stacking Ensemble
 (Meta-learner: XGBoost)
        â”‚
        â–¼
 Explainability Layer (LIME)
        â”‚
        â–¼
 LLM Integration (Sonar Pro)
 â†’ Converts LIME output into human-readable text
```

---

## âš™ï¸ Tools & Technologies

| Layer | Tool / Library | Purpose |
|-------|----------------|----------|
| **Language** | Python | Core implementation |
| **Data Processing** | pandas, numpy | Cleaning, encoding, scaling |
| **Modeling** | scikit-learn, XGBoost | Classification & stacking ensemble |
| **Resampling** | SMOTE (imblearn) | Handle class imbalance |
| **Explainability** | LIME | Feature-level interpretability |
| **AI Insights** | Sonar Pro (LLM) | Natural-language explanation of predictions |
| **Visualization** | matplotlib, seaborn | Charts & confusion matrices |
| **Evaluation** | sklearn.metrics | Accuracy, Precision, Recall, F1-score |
| **IDE** | Jupyter Notebook | Interactive analysis |

---

## ğŸ§± Model Architecture & Components

### âš¡ 1ï¸âƒ£ Stacked Ensemble Learning
Combines multiple base learners:
- Logistic Regression  
- Decision Tree  
- Random Forest  
- AdaBoost  
- XGBoost  
**Meta Learner:** XGBoost  

âœ… Achieved **91% accuracy**, outperforming individual models.

---

### ğŸ§© 2ï¸âƒ£ Explainable AI (LIME)
- Provides **local explanations** for each prediction.  
- Identifies which features (e.g., *City*, *State*, *Transaction_Device*) contributed to a decision.  
- Enables **model transparency** for auditors & analysts.

---

### ğŸ§  3ï¸âƒ£ Large Language Model (Sonar Pro Integration)
- Converts LIME outputs into **clear natural-language narratives**.  
- Example:  
  > â€œThe transaction was flagged as fraud due to unusual city and device patterns, despite a safe branch type.â€

This boosts **trust, interpretability, and compliance-readiness**.

---

## ğŸ“Š Results Summary

| Model | Accuracy | Precision | Recall | F1-Score |
|--------|-----------|------------|----------|-----------|
| Logistic Regression | 64% | 0.61 | 0.63 | 0.62 |
| Random Forest | 73% | 0.72 | 0.73 | 0.72 |
| Decision Tree | 84% | 0.85 | 0.84 | 0.84 |
| AdaBoost | 77% | 0.78 | 0.76 | 0.77 |
| XGBoost | 88% | 0.87 | 0.88 | 0.88 |
| ğŸ¥‡ **Stacking Classifier** | **91%** | **0.90** | **0.92** | **0.91** |

---

## ğŸ“¦ Repository Structure

```
Financial-Fraud-Detection-Using-LIME-and-LLM/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ bank_fraud_transactions.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 1_preprocessing_visualization.ipynb
â”‚   â”œâ”€â”€ 2_model_training.ipynb
â”‚   â”œâ”€â”€ 3_lime_explainability.ipynb
â”‚   â””â”€â”€ 4_llm_integration.ipynb
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ stacking_model.pkl
â”‚   â”œâ”€â”€ xgboost_model.pkl
â”‚   â””â”€â”€ random_forest_importance.csv
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ confusion_matrices.png
â”‚   â”œâ”€â”€ lime_explanations.png
â”‚   â””â”€â”€ performance_summary.csv
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ§° Setup Instructions

### 1ï¸âƒ£ Clone Repository
```bash
git clone https://github.com/YandapalliVarunSai/Financial-Fraud-Detection-Using-LIME-and-LLM.git
cd Financial-Fraud-Detection-Using-LIME-and-LLM
```

### 2ï¸âƒ£ Create Virtual Environment
```bash
python -m venv venv
source venv/bin/activate  # (Windows: venv\Scripts\activate)
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Run Jupyter Notebook
```bash
jupyter notebook
```

Then open the `.ipynb` files inside the `notebooks/` folder.

---

## ğŸ“Š Key Visualizations

| Visualization | Description |
|----------------|-------------|
| Confusion Matrices | Model classification performance |
| Feature Importance | Top 15 predictors via Random Forest |
| LIME Charts | Local feature impact visualization |
| Accuracy Table | Model performance comparison |
| Natural Language Insight | LLM summary of predictions |

---

## ğŸ§© Key Learnings

- Ensemble methods improve **robustness** and **accuracy**.  
- **SMOTE** effectively handles severe class imbalance.  
- **LIME** adds interpretability at instance-level.  
- **LLM** integration bridges the gap between **technical and business insights**.  
- Transparency and explainability increase **regulatory trust**.

---

## ğŸ”® Future Work

- [ ] Extend dataset across multiple banks  
- [ ] Integrate **deep learning (LSTM/Transformers)** for sequence modeling  
- [ ] Implement **real-time fraud detection APIs**  
- [ ] Explore **global explainability** (SHAP)  
- [ ] Deploy via **Streamlit or Flask dashboard**

---

## ğŸ‘¤ Author

**Varun Sai Yandapalli**  
